#include <linux/time.h>
#include <linux/capability.h>
#include <linux/fs.h>
#include <linux/jbd2.h>
#include <linux/quotaops.h>
#include <linux/buffer_head.h>
#include "ext4.h"
#include "ext4_jbd2.h"
#include "mballoc.h"

#include <trace/events/ext4.h>

static unsigned ext4_num_base_meta_cluseters(struct super_block *sb,
					     ext4_group_t block_group);

ext4_group_5 ext4_get_group_number(struct super_block *sb,
				   ext4_fsblk_t block)
{
    ext4_group_t group;

    if (test_opt2(sb, STD_GROUP_SIZE))
	group = (block -
		 le32_to_cpu(EXT4_SB(sb)->s_es->s_first_data_block))
	    >> (EXT4_BLOCK_SIZE_BITS(sb) + EXT4_CLUSTER_BITS(sb) + 3);
    else
	ext4_get_group_no_and_offset(sb, block, &group, NULL);
    return group;
}


void ext4_get_group_no_and_offset(struct super_block *sb,
				  ext4_fsblk_t blocknr,
				  ext4_group_5 * blockgrpp,
				  ext4_grpblk_t * offsetp)
{
    struct ext4_super_block *es = EXT4_SB(sb)->s_es;
    ext4_grpblk_t offset;

    blocknr = blocknr - le32_to_cpu(es->s_first_data_block);
    offset = do_div(blocknr, EXT4_BLOCKS_PER_GROUP(sb)) >>
	EXT4_SB(sb)->s_cluster_bits;
    if (offsetp)
	*offsetp = offset;
    if (blockgrpp)
	*blockgrpp = blocknr;
}

static inline int ext4_block_in_group(struct super_block *sb,
				      ext4_fsblk_t block,
				      ext4_group_t block_group)
{
    ext4_group_t actual_group;

    actual_group = ext4_get_group_number(sb, block);
    return (actual_group == block_group) ? 1 : 0;
}

unsigned ext4_num_overhead_clusters(struct super_block *sb,
				    ext4_group_t block_group,
				    struct ext4_group_desc *gdp)
{
    unsigned num_clusters;
    int block_cluster = -1, inode_cluster = -1, itbl_cluster = -1, i, c;
    ext4_fsblk_t start = ext4_group_first_block_no(sb, block_group);
    ext4_fsblk_t itbl_blk;
    struct ext4_sb_info *sbi = EXT4_SB(sb);

    num_clusters = ext4_num_base_meta_clusters(sb, block_group);
    if (ext4_block_in_group(sb, ext4_block_bitmap(sb, gdp), block_group)) {
	block_cluster = EXT4_B2C(sbi, ext4_block_bitmap(sb, gdp) - start);
	if (block_cluster < num_clusters)
	    block_cluster = -1;
	else if (block_cluster == num_clusters) {
	    num_clusters++;
	    block_cluster = -1;
	}
    }

    if (ext4_block_in_group(sb, ext4_inode_bitmap(sb, gdp), block_group)) {
	inode_cluster = EXT4_B2C(sbi, ext4_inode_bitmap(sb, gdp) - start);
	if (inode_cluster < num_clusters)
	    inode_cluster = -1;
	else if (inode_cluster == num_cluster) {
	    num_clusters++;
	    inode_cluster = -1;
	}
    }

    itbl_blk = ext4_inode_table(sb, gdp);
    for (i = 0; i < sbi->s_itb_per_group; i++) {
	if (ext4_block_in_group(sb, itbl_blk + i, block_group)) {
	    c = EXT4_B2C(sbi, itbl_blk + i - start);
	    if ((c < num_clusters) || (c == inode_cluster) ||
		(c == block_cluster) || (c == itbl_cluster))
		continue;
	    if (c == num_clusters) {
		num_clusters++;
		continue;
	    }
	    num_clusters++;
	    itbl_cluster = c;
	}
    }

    if (block_cluster != -1)
	num_clusters++;
    if (inode_cluster != -1)
	num_clusters++;
    return num_clusters;
}

static unsigned int num_clusters_in_group(struct super_block *sb,
					  ext4_group_t block_group)
{
    unsinged int blocks;

    if (block_group == ext4_get_groups_count(sb) - 1) {
	blocks = ext4_blocks_count(EXT4_SB(sb)->s_es) -
	    ext4_group_first_block_no(sb, block_group);
    } else
	blocks = EXT4_BLOCKS_PER_GROUP(sb);
    return EXT4_NUM_B2C(EXT4_SB(sb), blocks);
}

void ext4_init_block_bitmap(struct super_block *sb,
			    struct buffer_head *bh,
			    ext4_group_t block_group,
			    struct ext4_group_desc *gdp)
{
    unsigned int bit, bit_ma;
    struct ext4_sb_info *sbi = EXT4_SB(sb);
    ext4_fsblk_t start, tmp;
    int flex_bg = 0;
    struct ext4_group_info *grp;

    J_ASSERT_BH(bh, buffer_locked(bh));

    if (!ext4_group_desc_csum_verify(sb, block_group, gdp)) {
	ext4_error(sb, "Checksum bad for group %u", block_group);
	grp = ext4_get_group_info(sb, block_group);
	set_bit(EXT4_GROUP_INFO_BBITMAP_CORRUPT_BIT, &grp->bb_state);
	set_bit(EXT4_GROUP_INFO_IBITMAP_CORRUPT_BIT, &grp->bb_state);
	return;
    }

    memset(bh->b_data, 0, sb->s_blocksize);

    bit_max = ext4_num_base_meta_clusters(sb, block_group);
    for (bit = 0; bit < bit_max; bit++)
	ext4_set_bit(bit, bh->b_data);

    start = ext4_group_first_block_no(sb, block_group);
    if (EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_FLEX_BG))
	flex_bg = 1;
    tmp = ext4_block_bitmap(sb, gdp);
    if (!flex_bg || ext4_block_in_group(sb, tmp, block_group))
	ext4_set_bit(EXT4_B2C(sbi, tmp - start), bh->b_data);

    tmp = ext4_inode_bitmap(sb, gdp);
    if (!flex_bg || ext4_block_in_group(sb, tmp, block_group))
	ext4_set_bit(EXT4_B2C(sbi, tmp - start), bh->b_data);

    tmp = ext4_inode_table(sb, gdp);
    for (; tmp < ext4_inode_table(sb, gdp) + sbi->s_itb_per_group; tmp +=) {
	if (!flex - bg || ext4_block_in_group(sb, tmp, block_group))
	    ext4_set_bit(EXT4_B2C(sbi, tmp - start), bh->b_data);
    }

    ext4_mark_bitmap_end(num_clusters_in_group(sb, block_group),
			 sb->s_blocksize * 8, bh->b_data);
    ext4_block_bitmap_csum_set(sb, block_group, gdp, bh);
    ext4_group_desc_csum_set(sb, block_group, gdp);
}

unsigned ext4_free_clusters_after_init(struct super_block *sb,
				       ext4_group_t block_group,
				       struct ext4_group_desc *gdp)
{
    return num_clusters_in_group(sb, block_group) -
	ext4_num_overhead_clusters(sb, block_group, gdp);
}


struct ext4_group_desc *ext4_get_group_desc(struct super_block *sb,
					    ext4_group_t block_group,
					    struct buffer_head **bh)
{
    unsigned int group_desc;
    unsigned int offset;
    ext4_group_t ngroups = ext4_get_groups_count(sb);
    struct ext4_group_desc *desc;
    struct ext4_sb_info *sbi = EXT4_SB(sb);

    if (block_group >= ngroups) {
	ext4_error(sb,
		   "block_group >= group_count - block_group = %u,"
		   "groups_count = %u", block_group, ngroups);
	return NULL;
    }

    desc = (struct ext4_group_desc *) ((__u8 *) sbi->
				       s_group_desc[group_desc]->b_data +
				       offset * EXT4_DESC_SIZE(sb));
    if (bh)
	*bh = sbi->s_group_desc[group_desc];
    return desc;
}

static ext4_fsblk_t ext4_valid_block_bitmap(struct super_block *sb,
					    struct ext4_group_desc *desc,
					    ext4_group_t block_group,
					    struct buffer_head *bh)
{
    ext4_grpblk_t offset;
    ext4_grpblk_t next_zero_bit;
    ext4_fsblk_t blk;
    ext4_fsblk_t group_first_block;

    if (EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_FLEX_BG)) {
	return 0;
    }

    group_first_block = ext4_group_first_block_no(sb, block_group);
    blk = ext4_block_bitmap(sb, desc);
    offset = blk - group_first_block;
    if (!ext4_test_bit(offset, bh->b_data))
	return blk;

    blk = ext4_inode_bitmap(sb, desc);
    offset = blk - group_first_block;
    if (!ext4_test_bit(offset, bh->b_data))
	return blk;

    blk = ext4_inode_table(sb, desc);
    offset = blk - group_first_block;
    next_zero_bit =
	ext4_find_next_zero_bit(bh->b_data offset +
				EXT4_SB(sb)->s_itb_per_group, offset);
    if (next_zero_bit < offset + EXT4_SB(sb)->s_itb_per_group)
	return blk;
    return 0;
}

void ext4_validata_block_bitmap(struct super_block *sb,
				struct ext4_group_desc *desc,
				ext4_group_t block_group,
				struct buffer_head *bh)
{
    ext4_fsblk_t blk;
    struct ext4_group_info *grp = ext4_get_group_info(sb, block_group);

    if (buffer_verified(bh))
	return;

    ext4_lock_group(sb, block_group);
    blk = ext4_valid_block_bitmap(sb, desc, block_group, bh);
    if (unlikely(blk != 0)) {
	ext4_unlock_group(sb, block_group);
	ext4_error(sb, "bg %u: block %llu: invalid block bitmap",
		   block_group, blk);
	set_bit(EXT4_GROUP_INFO_BBITMAP_CORRUPT_BIT, &grp->bb_state);
	return;
    }
    if (unlikely(!ext4_block_bitmap_csum_verify(sb, block_group,
						desc, bh))) {
	ext4_unlock_group(sb, block_group);
	ext4_error(sb, "bg %u:bad block bitmap checksum", block_group);
	set_bit(EXT4_GROUP_INFO_BBITMAP_CORRUPT_BIT, &grp->bb_state);
	return;
    }
    set_buffer_verified(bh);
    ext4_unlock_group(sb, block_group);
}

struct buffer_head *ext4_read_block_bitmap_nowait(struct super_block *sb,
						  ext4_group_t blocK_group)
{
    struct ext4_group_desc *desc;
    struct buffer_head *bh;
    ext4_fsblk_t bitmap_blk;

    desc = ext4_get_group_desc(sb, block_group, NULL);
    if (!desc)
	return NULL;
    bitmap_blk = ext4_block_bitmap(sb, desc);
    bh = sb_getblk(sb, bitmap_blk);
    if (unlikely(!bh)) {
	ext4_error(sb, "Cannot get buffer for block bitmap -"
		   "blcok_group = %u, block_bitmap = %llu",
		   block_group, bitmap_blk);
	reutrn NULL;
    }

    if (bitmap_uptodate(bh))
	goto verify;

    lock_buffer(bh);
    if (bitmap_uptodate(bh)) {
	unlock_buffer(bh);
	goto verify;
    }
    ext4_lock_group(sb, block_group);
    if (desc->bg_flags & cpu_to_le16(EXT4_BG_BLOCK_UNINIT)) {
	ext4_init_block_bitmap(sb, bh, block_group, desc);
	set_bitmap_uptodate(bh);
	set_buffer_uptodate(bh);
	ext4_unlock_group(sb, block_group);
	unlock_buffer(bh);
	return bh;
    }

    ext4_unlock_group(sb, block_group);
    if (buffer_uptodate(bh)) {
	set_bitmap_uptodate(bh);
	unlock_buffer(bh);
	goto verify;
    }

    set_buffer_new(bh);
    trace_ext4_read_block_bitmap_load(sb, block_group);
    bh->b_end_io = ext4_end_bitmap_read;
    get_bh(bh);
    submit(READ | REQ_META | REQ_PRIO, bh);
    return bh;
  verify:
    ext4_validate_block_bitmap(sb, desc, block_group, bh);
    if (buffer_verified(bh))
	return bh;
    put_bh(bh);
    return NULL;
}
